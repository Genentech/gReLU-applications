{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c31446f3-a976-42a0-9dfb-bc873049464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import pandas as pd\n",
    "from grelu.lightning import LightningModel\n",
    "import pytorch_lightning as pl\n",
    "from grelu.sequence.utils import get_unique_length, resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e5daae-fe31-4cc7-b876-683768acd3cf",
   "metadata": {},
   "source": [
    "## set up wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c561ab-ba82-4718-abe9-96c44133b314",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mavantikalal\u001b[0m (\u001b[33mgrelu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(host=\"https://api.wandb.ai\", relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48cf7ec6-1b32-4f96-a0f1-c7ffb1cb5fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/code/github/gReLU-applications/borzoi/wandb/run-20250304_194954-rmyyv28v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grelu/borzoi/runs/rmyyv28v' target=\"_blank\">copy-mouse</a></strong> to <a href='https://wandb.ai/grelu/borzoi' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grelu/borzoi' target=\"_blank\">https://wandb.ai/grelu/borzoi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grelu/borzoi/runs/rmyyv28v' target=\"_blank\">https://wandb.ai/grelu/borzoi/runs/rmyyv28v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(entity='grelu', project='borzoi', job_type='copy', name='copy-mouse') # Initialize a W&B Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdb23c5-371e-4473-835c-cf21f82e610f",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556b9768-f3e4-466a-b097-0b3226e788dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_path = '/code/borzoi/data/targets_mouse.txt.gz'\n",
    "intervals_path = '/gstore/data/resbioai/grelu/borzoi-data/mm10/sequences.bed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c87dc-cacf-48f0-a081-5260e325cb7b",
   "metadata": {},
   "source": [
    "## Process tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8616dde-2567-4a3c-8fb9-de412d342078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2608\n"
     ]
    }
   ],
   "source": [
    "tasks = pd.read_table(tasks_path, index_col=0)\n",
    "print(len(tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f24ff2-74bc-41ee-9cc9-5cf9e75c2ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>file</th>\n",
       "      <th>clip</th>\n",
       "      <th>clip_soft</th>\n",
       "      <th>scale</th>\n",
       "      <th>sum_stat</th>\n",
       "      <th>strand_pair</th>\n",
       "      <th>description</th>\n",
       "      <th>assay</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNhs10464+</td>\n",
       "      <td>/home/drk/tillage/datasets/mouse/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>CAGE:placenta, adult pregnant day17</td>\n",
       "      <td>CAGE</td>\n",
       "      <td>placenta, adult pregnant day17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNhs10464-</td>\n",
       "      <td>/home/drk/tillage/datasets/mouse/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>0</td>\n",
       "      <td>CAGE:placenta, adult pregnant day17</td>\n",
       "      <td>CAGE</td>\n",
       "      <td>placenta, adult pregnant day17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name                                               file  clip  \\\n",
       "0  CNhs10464+  /home/drk/tillage/datasets/mouse/cage/fantom/C...   768   \n",
       "1  CNhs10464-  /home/drk/tillage/datasets/mouse/cage/fantom/C...   768   \n",
       "\n",
       "   clip_soft  scale sum_stat  strand_pair  \\\n",
       "0        384    1.0      sum            1   \n",
       "1        384    1.0      sum            0   \n",
       "\n",
       "                           description assay                          sample  \n",
       "0  CAGE:placenta, adult pregnant day17  CAGE  placenta, adult pregnant day17  \n",
       "1  CAGE:placenta, adult pregnant day17  CAGE  placenta, adult pregnant day17  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks=tasks.reset_index(drop=True)\n",
    "tasks[\"assay\"] = tasks[\"description\"].apply(lambda x: x.split(\":\")[0])\n",
    "tasks[\"assay\"].value_counts()\n",
    "tasks[\"sample\"] = tasks[\"description\"].apply(lambda x: \":\".join(x.split(\":\")[1:]))\n",
    "tasks = tasks.rename(columns={\"identifier\":\"name\"})\n",
    "tasks.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f96ecc7-238e-4707-a3af-64b0d1828bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = tasks.to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056ecfa-1b75-46b7-9e36-4e72c4cb3618",
   "metadata": {},
   "source": [
    "## Process intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e768d909-c699-47b6-86fd-c3ff54357c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>46257174</td>\n",
       "      <td>46453782</td>\n",
       "      <td>fold0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2</td>\n",
       "      <td>83512641</td>\n",
       "      <td>83709249</td>\n",
       "      <td>fold0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr7</td>\n",
       "      <td>16218353</td>\n",
       "      <td>16414961</td>\n",
       "      <td>fold0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr3</td>\n",
       "      <td>113724419</td>\n",
       "      <td>113921027</td>\n",
       "      <td>fold0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr3</td>\n",
       "      <td>107470140</td>\n",
       "      <td>107666748</td>\n",
       "      <td>fold0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom      start        end   fold\n",
       "0  chr1   46257174   46453782  fold0\n",
       "1  chr2   83512641   83709249  fold0\n",
       "2  chr7   16218353   16414961  fold0\n",
       "3  chr3  113724419  113921027  fold0\n",
       "4  chr3  107470140  107666748  fold0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals = pd.read_table(intervals_path, header=None)\n",
    "intervals.columns = ['chrom', 'start', 'end', 'fold']\n",
    "intervals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc4f093c-9d9d-4b0d-9883-050099492944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    36950\n",
       "val       6318\n",
       "test      6101\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals['split'] = 'train'\n",
    "intervals.loc[intervals.fold=='fold3', 'split'] = 'test'\n",
    "intervals.loc[intervals.fold=='fold4', 'split'] = 'val'\n",
    "intervals.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aafdb2e-93b3-406a-97fb-aab39d33aa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196608"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_length(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c45008d0-9dda-4660-8e1c-574570eef373",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = resize(intervals, 524288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86aae057-b106-4884-81b3-d1aa563ad4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_intervals = intervals[intervals.split=='train'].iloc[:, :3]\n",
    "val_intervals = intervals[intervals.split=='val'].iloc[:, :3]\n",
    "test_intervals = intervals[intervals.split=='test'].iloc[:, :3]\n",
    "del intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd10a9-40c2-4299-aa74-6474ea5a71ef",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06dba49d-11ba-471b-83d7-05fe45a9bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"model_type\":\"BorzoiModel\",\n",
    "    \"n_tasks\":2608,\n",
    "    \"final_act_func\": 'softplus',\n",
    "    \"final_pool_func\":None,\n",
    "    \"crop_len\":5120,\n",
    "}\n",
    "train_params={\n",
    "    \"task\":\"regression\",\n",
    "    \"loss\":\"mse\",\n",
    "}\n",
    "lm = LightningModel(model_params, train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a3055-d338-40f0-9fd3-f8f3134df643",
   "metadata": {},
   "source": [
    "## Save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4e54e05-aa9b-45b1-b33c-f28dad0425f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 524288])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from grelu.sequence.format import convert_input_type\n",
    "input = convert_input_type(['A'*524288], \"one_hot\")\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed4db121-d1bb-4c04-9448-03029f84b8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196608"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6144*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbccda9a-7a62-4472-9c0b-34abf98a7e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3287790/3322024732.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f\"/data/borzoi/torch_weights/mouse_fold{rep}.h5\")\n",
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/tmp/ipykernel_3287790/3322024732.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f\"/data/borzoi/torch_weights/mouse_fold{rep}.h5\")\n",
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/tmp/ipykernel_3287790/3322024732.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f\"/data/borzoi/torch_weights/mouse_fold{rep}.h5\")\n",
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/tmp/ipykernel_3287790/3322024732.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f\"/data/borzoi/torch_weights/mouse_fold{rep}.h5\")\n",
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    }
   ],
   "source": [
    "for rep in range(4):\n",
    "    state_dict = torch.load(f\"/data/borzoi/torch_weights/mouse_fold{rep}.h5\")\n",
    "    lm.model.load_state_dict(state_dict)\n",
    "    lm.data_params[\"tasks\"] = tasks\n",
    "\n",
    "    lm.data_params[\"train\"] = dict()\n",
    "    lm.data_params[\"val\"] = dict()\n",
    "    lm.data_params[\"test\"] = dict()\n",
    "    \n",
    "    lm.data_params[\"train\"][\"seq_len\"] = 524288\n",
    "    lm.data_params[\"train\"][\"label_len\"] = 6144*32\n",
    "    lm.data_params[\"train\"][\"genome\"] = \"hg38\"\n",
    "    lm.data_params[\"train\"][\"bin_size\"] = 32\n",
    "    \n",
    "    lm.data_params[\"train\"][\"intervals\"] = train_intervals.to_dict(orient='list')\n",
    "    lm.data_params[\"val\"][\"intervals\"] = val_intervals.to_dict(orient='list')\n",
    "    lm.data_params[\"test\"][\"intervals\"] = test_intervals.to_dict(orient='list')\n",
    "    \n",
    "    assert lm(input).shape == (1, 2608, 6144)\n",
    "    \n",
    "    trainer = pl.Trainer()\n",
    "    try:\n",
    "        trainer.predict(lm)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    trainer.save_checkpoint(f'/data/borzoi/torch_weights/mouse_rep{rep}.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5fbc09-abca-4cb7-a8b7-7eeba7b39cf8",
   "metadata": {},
   "source": [
    "## Upload to wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c53a69b4-9092-44b9-b8a9-20b72aa8b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata={\n",
    "            'model_params':lm.model_params, \n",
    "            'train_params':lm.train_params, \n",
    "            'data_params':lm.data_params\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a25b878-ca1f-4872-9549-ab502975ca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type list that is 312024 bytes\n"
     ]
    }
   ],
   "source": [
    "for rep in range(4):\n",
    "    ckpt = f'/data/borzoi/torch_weights/mouse_rep{rep}.ckpt'\n",
    "    artifact = wandb.Artifact(\n",
    "        f'mouse_rep{rep}', \n",
    "        type='model',\n",
    "        metadata=metadata,\n",
    "    )\n",
    "    artifact.add_file(ckpt)\n",
    "    run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98dd40ec-f276-4099-a4a7-39ccf1600a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">copy-mouse</strong> at: <a href='https://wandb.ai/grelu/borzoi/runs/rmyyv28v' target=\"_blank\">https://wandb.ai/grelu/borzoi/runs/rmyyv28v</a><br> View project at: <a href='https://wandb.ai/grelu/borzoi' target=\"_blank\">https://wandb.ai/grelu/borzoi</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250304_194954-rmyyv28v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d6a57-a2a1-495d-90ff-16508e4e236c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
